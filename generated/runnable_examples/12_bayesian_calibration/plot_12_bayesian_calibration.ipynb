{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nUsage of Bayesian inference\n==============================\n\nThe :class:`~.BayesTool` provides methods to perform the calibration\nunder uncertainties of a model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo.datasets.dataset import Dataset\nfrom numpy import random\nfrom openturns import ComposedDistribution\nfrom openturns import Uniform\nfrom strenum import StrEnum\n\nfrom vimseo.api import activate_logger\nfrom vimseo.tools.bayes.bayes_analysis import BayesTool\nfrom vimseo.tools.bayes.bayes_analysis_result import PosteriorChecks\nfrom vimseo.tools.statistics.statistics_tool import StatisticsTool\n\nrandom.seed(0)  # noqa: NPY002\n\nactivate_logger()\n\nN_MCMC = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) Set-up of the stochastic model\n==================================\nWe start loading the experimental data\nthat will be processed to calibrate models:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_modulus = random.logistic(150000, 8000, 8)  # noqa: NPY002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to calibrate several probabilistic models,\nthat is to say probability distributions,\nfor instance Normal, Weibull, Log-normal:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Models(StrEnum):\n    NORMAL = \"Normal\"\n    WEIBULL_MIN = \"WeibullMin\"\n    LOG_NORMAL = \"LogNormal\"\n\n\nanalysis_n = BayesTool(working_directory=\"normal_model\")\nanalysis_l = BayesTool(working_directory=\"lognormal_model\")\nanalysis_w = BayesTool(working_directory=\"weibullmin_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each model,\nit is necessary to define a prior.\nExcept for the Normal model,\nit is difficult to give an initial guess\nfor the Weibull and Lognormal model.\nTo achieve this goal,\nwe compute the frequentist estimates\nof the model parameters.\nThe result of the frequentist estimate for the Normal model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "statistic_tool = StatisticsTool()\ndataset = Dataset.from_array(data_modulus.reshape(-1, 1))\nresults_normal = statistic_tool.execute(\n    dataset=dataset, tested_distributions=[\"Normal\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this result, we set-up the prior:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_normal = ComposedDistribution([Uniform(110000, 160000), Uniform(2000, 12000)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly for the Weibull Min model:\nthe frequentist estimate:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results_weibull = statistic_tool.execute(\n    dataset=dataset, tested_distributions=[\"WeibullMin\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the corresponding prior:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_weibull = ComposedDistribution([\n    Uniform(2000, 30000),\n    Uniform(0.1, 5),\n    Uniform(130000, min(data_modulus)),\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And for the Log Normal model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results_lognormal = statistic_tool.execute(\n    dataset=dataset, tested_distributions=[\"LogNormal\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And corresponding prior:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_lognormal = ComposedDistribution([\n    Uniform(4, 15),\n    Uniform(0.01, 5),\n    Uniform(130000, min(data_modulus)),\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2) Executing Bayesian inference\n================================\nWe can now sample the posterior distribution\nof the parameters of the normal model,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_n.execute(\n    likelihood_dist=Models.NORMAL,\n    prior_dist=prior_normal,\n    data=data_modulus,\n    n_mcmc=N_MCMC,\n)\nanalysis_n.save_results()\nanalysis_n.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "of the parameters of the weibull model,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_w.execute(\n    likelihood_dist=Models.WEIBULL_MIN,\n    prior_dist=prior_weibull,\n    data=data_modulus,\n    n_mcmc=N_MCMC,\n)\nanalysis_w.save_results()\nanalysis_w.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "of the parameters of the lognormal model,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_l.execute(\n    likelihood_dist=Models.LOG_NORMAL,\n    prior_dist=prior_lognormal,\n    data=data_modulus,\n    n_mcmc=N_MCMC,\n)\nanalysis_l.save_results()\nanalysis_l.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we determine the burnin for each MCMC sampling.\nFirst for the Normal model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_n.plot_burnin(analysis_n.result, save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, the Weibull Min model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_w.plot_burnin(analysis_w.result, save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the Log Normal model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_l.plot_burnin(analysis_l.result, save=False, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A value of 50 for the burnin\nseems ok for sampler is thus selected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "burnin = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we post-process the results\nfor each models before analyzing the results,\nfirst for the Normal model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_n.post(50)\n# then for the Weibull Min model:\nanalysis_w.post(50)\n# And the Log Normal model:\nanalysis_l.post(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we generate the plots\nfor the Normal model,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figs_n = analysis_n.plot_results()\n# the Weibull Min model\nfigs_w = analysis_w.plot_results()\n# and the Log Normal model\nfigs_l = analysis_l.plot_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first conclusion\nthat can be drawn\nfrom the plots of the\nposterior samples\nfor each model is that\nthat priors were elicited.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3) Validating models\n==================================\nWe aim now to validate models.\nFrom the earlier posterior predictive plots,\nwe can perform qualitative analyses.\nThe posterior predictive distributions\nrefer to predictions for all models\naveraged over all posterior samples.\nThough the predictions\nfrom all models are rather coherent\nwith respect to the data,\nthose from the Normal model are not\nas relevant as for the others.\nIn particular,\nthey are symmetric\ncontrary to the data.\nIt is harder to discriminate\nbetween the two other models\nusing only visual plots.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To continue the analyses,\n# we study several numerical indicators,\n# lppds and marginal likelihoods.\n# We instanciate a class PosteriorChecks\n# to analyze and summarize the results,\ncheck_n = PosteriorChecks(analysis_n.result)\ncheck_l = PosteriorChecks(analysis_l.result)\ncheck_w = PosteriorChecks(analysis_w.result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aside from posterior predictive plots\nthat are qualitative assessments,\nwe can focus on quantitative metrics\nthat will account in particular\nfor the fact that the Weibull and Lognormal models\nhave higher number of parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(check_n)\nprint(check_w)\nprint(check_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consistently with earlier observations,\nthe Weibull model seems to have\nthe best predictive accuracy\naccording to the lppd.\nThe marginal likelihoods\nare harder to compare\nbecause the priors\nfor the Weibull and Lognormal models\nhave much wider support,\npenalizing thus heavily these models.\nIt is interesting to notice\nthat the ml for the Lognormal model\nin spite of a much wider support,\nhas a better predictive accuracy\nsufficiently larger to compensate\nthe difference from the priors.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4). The Weibull model\nand the Lognormal have 3 parameters\ninstead of 2 for the Normal\nwith the default parametrization\nof OpenTURNS distribution.\nWe try to calibrate these two models\nby freezing some parameters,\n(the location parameter)\nwhich is carried out\nby indicating the frozen parameters\nand their associated values.\n==================================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_weibull_b = ComposedDistribution([Uniform(50_000, 200_000), Uniform(1, 100)])\ndict_frozen = {\"frozen_index\": [2], \"frozen_values\": [0]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now sample as earlier\nthe posterior distribution\nof the parameters of the new models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_w_b = BayesTool(working_directory=\"weibullmin_2_frozen\")\nanalysis_w_b.execute(\n    likelihood_dist=Models.WEIBULL_MIN,\n    prior_dist=prior_weibull_b,\n    data=data_modulus,\n    n_mcmc=N_MCMC,\n    frozen_variables=dict_frozen,\n)\nanalysis_w_b.save_results()\n\nprior_lognormal_b = ComposedDistribution([Uniform(2, 20), Uniform(0.005, 0.5)])\nanalysis_l_b = BayesTool(working_directory=\"lognormal_2_frozen\")\nanalysis_l_b.execute(\n    likelihood_dist=Models.LOG_NORMAL,\n    prior_dist=prior_lognormal_b,\n    data=data_modulus,\n    n_mcmc=N_MCMC,\n    frozen_variables=dict_frozen,\n)\nanalysis_l_b.save_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe determine the burnin for each MCMC sampling:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis_w_b.plot_burnin(analysis_w_b.result, save=True, show=True)\nanalysis_l_b.plot_burnin(analysis_l_b.result, save=True, show=True)\n\n# Finally,\n# as earlier,\n# we launch several\n# post-processing analyses:\nanalysis_w_b.post(50)\n# And the Log Normal model:\nanalysis_l_b.post(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the Weibull Min model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figs_w_b = analysis_w_b.plot_results()\n# and the Log Normal model\nfigs_l_b = analysis_l_b.plot_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nfor each model,\nthe posterior samples\nare not uniformly distributed\nshowing that priors were elicited.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Furthermore,\n# posterior predictive plots show\n# that with a smaller number\n# of degrees of freedom,\n# the Weibull seems less appropriate\n# than the Lognormal model.\n\n\n# Finally, we instanciate\n# the new checks:\ncheck_l_b = PosteriorChecks(analysis_l_b.result)\ncheck_w_b = PosteriorChecks(analysis_w_b.result)\n\n# We can compute next the different criteria\n# for the different models.\nprint(check_n)\nprint(check_w_b)\nprint(check_l_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By removing a degree of freedom\nthe Weibull model becomes less accurate,\nThe downgrade for the Lognormal model\nis not as significant.\nThese conclusions are consistent\nwith the observations\nfrom the posterior predictive plots.\nThe marginal likelihoods\nare harder to compare\nbecause the priors\nare not compatible,\neither wider (Lognormal model)\nor smaller (Weibull model).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}