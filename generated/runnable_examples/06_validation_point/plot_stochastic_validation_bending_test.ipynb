{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nAn example of stochastic validation point\n=========================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport logging\nfrom pathlib import Path\n\nfrom gemseo.datasets.io_dataset import IODataset\nfrom pandas import read_csv\n\nfrom vimseo import EXAMPLE_RUNS_DIR_NAME\nfrom vimseo.api import activate_logger\nfrom vimseo.api import create_model\nfrom vimseo.core.model_settings import IntegratedModelSettings\nfrom vimseo.io.space_io import SpaceToolFileIO\nfrom vimseo.material.material import Material\nfrom vimseo.material_lib import MATERIAL_LIB_DIR\nfrom vimseo.storage_management.base_storage_manager import PersistencyPolicy\nfrom vimseo.tools.space.space_tool_result import SpaceToolResult\nfrom vimseo.tools.validation.validation_point import NominalValuesOutputType\nfrom vimseo.tools.validation.validation_point import StochasticValidationPoint\nfrom vimseo.tools.validation.validation_point import StochasticValidationPointInputs\nfrom vimseo.tools.validation.validation_point import StochasticValidationPointSettings\nfrom vimseo.tools.validation.validation_point import read_nominal_values\nfrom vimseo.utilities.datasets import SEP\nfrom vimseo.utilities.generate_validation_reference import Bias\nfrom vimseo.utilities.generate_validation_reference import (\n    generate_reference_from_parameter_space,\n)\n\nactivate_logger(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we generate synthetic reference data,\nusing an analytical bending test model, and bias\nthe output of interest by 5 \\%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_name = \"BendingTestAnalytical\"\nload_case = \"Cantilever\"\ntarget_model = create_model(\n    model_name,\n    load_case,\n    model_options=IntegratedModelSettings(\n        directory_archive_persistency=PersistencyPolicy.DELETE_ALWAYS,\n        directory_scratch_persistency=PersistencyPolicy.DELETE_ALWAYS,\n    ),\n)\ntarget_model.cache = None\nreference_dataset_cantilever = generate_reference_from_parameter_space(\n    target_model,\n    SpaceToolFileIO()\n    .read(file_name=\"bending_test_validation_input_space.json\")\n    .parameter_space,\n    n_samples=6,\n    input_names=[\"width\", \"height\"],\n    output_names=[\"reaction_forces\", \"maximum_dplt\"],\n    outputs_to_bias={\"reaction_forces\": Bias(mult_factor=1.05)},\n    additional_name_to_data={\"nominal_length\": 600.0, \"batch\": 1},\n)\nreference_dataset_cantilever.to_csv(\n    \"reference_validation_bending_test_cantilever.csv\", sep=SEP\n)\nprint(\"The reference data: \", reference_dataset_cantilever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objective is to validate a model for a new material.\nLet's create a model to validate:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_model(\n    model_name,\n    load_case,\n    model_options=IntegratedModelSettings(\n        directory_archive_root=f\"../../../{EXAMPLE_RUNS_DIR_NAME}/archive/validation_point\",\n        directory_scratch_root=f\"../../../{EXAMPLE_RUNS_DIR_NAME}/scratch/validation_point\",\n        cache_file_path=f\"../../../{EXAMPLE_RUNS_DIR_NAME}/caches/validation_point/{model_name}_{load_case}_cache.hdf\",\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the material, which defines probability distributions for its properties.\nIt is typically obtained from a calibration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "material = Material.from_json(MATERIAL_LIB_DIR / \"Ta6v.json\")\nprint(\"The stochastic material: \", material)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the measured quantities of interest\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "measured_inputs = [\"width\", \"height\", \"imposed_dplt\"]\nmeasured_outputs = [\"reaction_forces\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since reference data are referenced by batches,\nwe can select a batch to perform the validation only regarding this batch:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the path to the reference data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "csv_path = \"reference_validation_bending_test_cantilever.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the nominal inputs\nat which the validation point is performed.\nThe ``read_nominal_values`` function allows to read\nthe nominal values in the reference data, using averaging\nover the repeats for a given ``master`` variable:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nominal_values = read_nominal_values(\n    \"batch\",\n    csv_path=csv_path,\n    master_value=batch,\n    additional_names=[\"nominal_length\"],\n    name_remapping={\"nominal_length\": \"length\"},\n    output_type=NominalValuesOutputType.DICTIONARY,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed-up the example, we coarsen the mesh:\nnominal_values.update({\"element_size\": atleast_1d(4.32)})\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally we set the nominal inputs from the material.\nIndeed, all material properties may not be stochastic\n(a distribution is not necessarily defined).\nAs a result, we need to set the model default inputs\nto the deterministic property values.\nIt is done through the nominal inputs:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nominal_values.update(material.get_values_as_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reference samples are then defined from the csv file containing the measured data.\nFirst, the data are filtered to retain only the considered batch:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = read_csv(\n    csv_path,\n    delimiter=SEP,\n)\ndf = df[df[\"batch\"] == batch]\ndf.to_csv(\"filtered_reference_data.csv\", sep=SEP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then the groups to which the measured inputs and measured QoIs belong are defined,\nand the filtered data is loaded as a GEMSEO ``Dataset``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "variable_names_to_group_names = dict.fromkeys(measured_inputs, IODataset.INPUT_GROUP)\nvariable_names_to_group_names.update(\n    dict.fromkeys(measured_outputs, IODataset.OUTPUT_GROUP)\n)\nvalidation_dataset = IODataset.from_txt(\n    \"filtered_reference_data.csv\",\n    header=True,\n    delimiter=SEP,\n    variable_names_to_group_names=variable_names_to_group_names,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The uncertainties coming from unmeasured inputs are then taken into account\nvia the argument ``uncertain_input_space``, to which we pass a parameter\nspace defined from the material.\nThe stochastic validation point can now be created and executed.\nThe model output uncertainty is estimated by sampling the input space\nwith ``n_samples`` points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "validation_point_tool = StochasticValidationPoint(\n    working_directory=Path(f\"{model_name}_{load_case}\")\n    / f\"batch_{batch}_{nominal_values['length']}\",\n)\nvalidation_point_tool.execute(\n    inputs=StochasticValidationPointInputs(\n        model=model,\n        measured_data=validation_dataset,\n        uncertain_input_space=material.to_parameter_space(),\n    ),\n    settings=StochasticValidationPointSettings(\n        metric_names=[\n            \"AreaMetric\",\n            \"RelativeAreaMetric\",\n            \"RelativeMeanToMean\",\n            \"AbsoluteRelativeErrorP90\",\n        ],\n        nominal_data=nominal_values,\n        n_samples=4,\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation results can be saved on disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "validation_point_tool.save_results(prefix=f\"batch_{batch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results can be plotted:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figures = validation_point_tool.plot_results(\n    validation_point_tool.result, \"reaction_forces\", show=True, save=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Q-Q plot of the measured and simulated distributions:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figures[\"qq_plot\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The comparison of the measured and simulated PDF:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figures[\"PDF_comparison\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The comparison of the measured and simulated CDF:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figures[\"CDF_comparison\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The saved result can be visualised in a dashboard by typing in a terminal\nwhere the vims_composites Python environment is activated:\n``dashboard_validation_point_viewer``\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The simulated input space can be exported to disk, to be visualized with\n``dashboard_space``.\nIn pickle format:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "space_tool_result = SpaceToolResult(\n    parameter_space=validation_point_tool.simulated_input_space\n)\nspace_tool_result.to_pickle(\"simulated_input_space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or in json format:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SpaceToolFileIO().write(space_tool_result, file_base_name=\"simulated_input_space\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}